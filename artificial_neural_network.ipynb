{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMT_xQXF85AE"
      },
      "source": [
        "# Build an Artificial Neural Network\n",
        "## Classifying Dates \n",
        "In this project, we will build a neural network to classify dates. We'll use the ‚ÄúDate Fruit Dataset‚Äù available on Kaggle for this. This dataset includes samples of dates that can be classified into 7 classes according to their types."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVctqtiXg1AF"
      },
      "source": [
        "## Importing the required libraries\n",
        "We'll start with importing required libraries.\n",
        "\n",
        "üìå Use the keywords \"import\" and \"from\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0IPLr7JHg0wn"
      },
      "outputs": [],
      "source": [
        "# Import Pandas and Matplotlib\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "# Import Label Encoder and train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, minmax_scale\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcMYUXN-cykx"
      },
      "source": [
        "## Dataset\n",
        "Let's load the .xlsx file.\n",
        "\n",
        "üìå Use the read_excel() function of the Pandas library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vzD6tUiPg6hl"
      },
      "outputs": [],
      "source": [
        "# Read the \"date_fruit.xlsx\" file\n",
        "data = pd.read_excel(\"date_fruit.xlsx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNjjBGzIcvAb"
      },
      "source": [
        "Next, we take a look at the dataset.\n",
        "\n",
        "üìå Use the data.head() function.\n",
        "\n",
        "üìå Use .shape attribute and .unique() methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tCmbPFCQhCW3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "7622cfcf-0574-4cc3-c2c7-6b55a71764ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     AREA  PERIMETER  MAJOR_AXIS  MINOR_AXIS  ECCENTRICITY   EQDIASQ  \\\n",
              "0  422163   2378.908    837.8484    645.6693        0.6373  733.1539   \n",
              "1  338136   2085.144    723.8198    595.2073        0.5690  656.1464   \n",
              "2  526843   2647.394    940.7379    715.3638        0.6494  819.0222   \n",
              "3  416063   2351.210    827.9804    645.2988        0.6266  727.8378   \n",
              "4  347562   2160.354    763.9877    582.8359        0.6465  665.2291   \n",
              "\n",
              "   SOLIDITY  CONVEX_AREA  EXTENT  ASPECT_RATIO  ...  KurtosisRR  KurtosisRG  \\\n",
              "0    0.9947       424428  0.7831        1.2976  ...      3.2370      2.9574   \n",
              "1    0.9974       339014  0.7795        1.2161  ...      2.6228      2.6350   \n",
              "2    0.9962       528876  0.7657        1.3150  ...      3.7516      3.8611   \n",
              "3    0.9948       418255  0.7759        1.2831  ...      5.0401      8.6136   \n",
              "4    0.9908       350797  0.7569        1.3108  ...      2.7016      2.9761   \n",
              "\n",
              "   KurtosisRB    EntropyRR    EntropyRG    EntropyRB  ALLdaub4RR  ALLdaub4RG  \\\n",
              "0      4.2287 -59191263232 -50714214400 -39922372608     58.7255     54.9554   \n",
              "1      3.1704 -34233065472 -37462601728 -31477794816     50.0259     52.8168   \n",
              "2      4.7192 -93948354560 -74738221056 -60311207936     65.4772     59.2860   \n",
              "3      8.2618 -32074307584 -32060925952 -29575010304     43.3900     44.1259   \n",
              "4      4.4146 -39980974080 -35980042240 -25593278464     52.7743     50.9080   \n",
              "\n",
              "   ALLdaub4RB  Class  \n",
              "0     47.8400  BERHI  \n",
              "1     47.8315  BERHI  \n",
              "2     51.9378  BERHI  \n",
              "3     41.1882  BERHI  \n",
              "4     42.6666  BERHI  \n",
              "\n",
              "[5 rows x 35 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ccff7fdb-6dbe-42ff-861b-68a5e38bf720\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AREA</th>\n",
              "      <th>PERIMETER</th>\n",
              "      <th>MAJOR_AXIS</th>\n",
              "      <th>MINOR_AXIS</th>\n",
              "      <th>ECCENTRICITY</th>\n",
              "      <th>EQDIASQ</th>\n",
              "      <th>SOLIDITY</th>\n",
              "      <th>CONVEX_AREA</th>\n",
              "      <th>EXTENT</th>\n",
              "      <th>ASPECT_RATIO</th>\n",
              "      <th>...</th>\n",
              "      <th>KurtosisRR</th>\n",
              "      <th>KurtosisRG</th>\n",
              "      <th>KurtosisRB</th>\n",
              "      <th>EntropyRR</th>\n",
              "      <th>EntropyRG</th>\n",
              "      <th>EntropyRB</th>\n",
              "      <th>ALLdaub4RR</th>\n",
              "      <th>ALLdaub4RG</th>\n",
              "      <th>ALLdaub4RB</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>422163</td>\n",
              "      <td>2378.908</td>\n",
              "      <td>837.8484</td>\n",
              "      <td>645.6693</td>\n",
              "      <td>0.6373</td>\n",
              "      <td>733.1539</td>\n",
              "      <td>0.9947</td>\n",
              "      <td>424428</td>\n",
              "      <td>0.7831</td>\n",
              "      <td>1.2976</td>\n",
              "      <td>...</td>\n",
              "      <td>3.2370</td>\n",
              "      <td>2.9574</td>\n",
              "      <td>4.2287</td>\n",
              "      <td>-59191263232</td>\n",
              "      <td>-50714214400</td>\n",
              "      <td>-39922372608</td>\n",
              "      <td>58.7255</td>\n",
              "      <td>54.9554</td>\n",
              "      <td>47.8400</td>\n",
              "      <td>BERHI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>338136</td>\n",
              "      <td>2085.144</td>\n",
              "      <td>723.8198</td>\n",
              "      <td>595.2073</td>\n",
              "      <td>0.5690</td>\n",
              "      <td>656.1464</td>\n",
              "      <td>0.9974</td>\n",
              "      <td>339014</td>\n",
              "      <td>0.7795</td>\n",
              "      <td>1.2161</td>\n",
              "      <td>...</td>\n",
              "      <td>2.6228</td>\n",
              "      <td>2.6350</td>\n",
              "      <td>3.1704</td>\n",
              "      <td>-34233065472</td>\n",
              "      <td>-37462601728</td>\n",
              "      <td>-31477794816</td>\n",
              "      <td>50.0259</td>\n",
              "      <td>52.8168</td>\n",
              "      <td>47.8315</td>\n",
              "      <td>BERHI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>526843</td>\n",
              "      <td>2647.394</td>\n",
              "      <td>940.7379</td>\n",
              "      <td>715.3638</td>\n",
              "      <td>0.6494</td>\n",
              "      <td>819.0222</td>\n",
              "      <td>0.9962</td>\n",
              "      <td>528876</td>\n",
              "      <td>0.7657</td>\n",
              "      <td>1.3150</td>\n",
              "      <td>...</td>\n",
              "      <td>3.7516</td>\n",
              "      <td>3.8611</td>\n",
              "      <td>4.7192</td>\n",
              "      <td>-93948354560</td>\n",
              "      <td>-74738221056</td>\n",
              "      <td>-60311207936</td>\n",
              "      <td>65.4772</td>\n",
              "      <td>59.2860</td>\n",
              "      <td>51.9378</td>\n",
              "      <td>BERHI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>416063</td>\n",
              "      <td>2351.210</td>\n",
              "      <td>827.9804</td>\n",
              "      <td>645.2988</td>\n",
              "      <td>0.6266</td>\n",
              "      <td>727.8378</td>\n",
              "      <td>0.9948</td>\n",
              "      <td>418255</td>\n",
              "      <td>0.7759</td>\n",
              "      <td>1.2831</td>\n",
              "      <td>...</td>\n",
              "      <td>5.0401</td>\n",
              "      <td>8.6136</td>\n",
              "      <td>8.2618</td>\n",
              "      <td>-32074307584</td>\n",
              "      <td>-32060925952</td>\n",
              "      <td>-29575010304</td>\n",
              "      <td>43.3900</td>\n",
              "      <td>44.1259</td>\n",
              "      <td>41.1882</td>\n",
              "      <td>BERHI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>347562</td>\n",
              "      <td>2160.354</td>\n",
              "      <td>763.9877</td>\n",
              "      <td>582.8359</td>\n",
              "      <td>0.6465</td>\n",
              "      <td>665.2291</td>\n",
              "      <td>0.9908</td>\n",
              "      <td>350797</td>\n",
              "      <td>0.7569</td>\n",
              "      <td>1.3108</td>\n",
              "      <td>...</td>\n",
              "      <td>2.7016</td>\n",
              "      <td>2.9761</td>\n",
              "      <td>4.4146</td>\n",
              "      <td>-39980974080</td>\n",
              "      <td>-35980042240</td>\n",
              "      <td>-25593278464</td>\n",
              "      <td>52.7743</td>\n",
              "      <td>50.9080</td>\n",
              "      <td>42.6666</td>\n",
              "      <td>BERHI</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 35 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ccff7fdb-6dbe-42ff-861b-68a5e38bf720')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ccff7fdb-6dbe-42ff-861b-68a5e38bf720 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ccff7fdb-6dbe-42ff-861b-68a5e38bf720');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Use the head() function to display the first 5 rows of the data\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "oPZLZ3TNyp0S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26070bd4-84b2-4e85-93ba-48740dc2a724"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(898, 35)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['BERHI', 'DEGLET', 'DOKOL', 'IRAQI', 'ROTANA', 'SAFAVI', 'SOGAY'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Print the shape of the data and classes\n",
        "print(data.shape)\n",
        "data[\"Class\"].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHRqIV5oc11d"
      },
      "source": [
        "## Preprocessing\n",
        "\n",
        "Now that we have a better understanding of our data, let‚Äôs split the dataset into features and labels.\n",
        "\n",
        "üìå Create X and y datasets using .drop() and .loc() methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GIfZOgi8hCUe"
      },
      "outputs": [],
      "source": [
        "# Create the features dataset\n",
        "X = data.drop(\"Class\",axis=1)\n",
        "\n",
        "# Create the labels dataset\n",
        "y = data.loc[:, \"Class\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGJWgaFAtTwR"
      },
      "source": [
        "### Feature scaling\n",
        "\n",
        "Having features in different units or ranges can be problematic in deep learning. We need to scale all of the values between the 0 and 1 range.\n",
        "\n",
        "üìå Use the minmax_scale() function of the sklearn library.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8-EJKybGao0M"
      },
      "outputs": [],
      "source": [
        "# Normalize the features dataset and assign it to a variable\n",
        "X_scaled = minmax_scale(X)\n",
        "\n",
        "# Create a DataFrame using the new variable\n",
        "X = pd.DataFrame(X_scaled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXmMewPc52gj"
      },
      "source": [
        "Then, we print the X data again so we can see the difference.\n",
        "\n",
        "üìå Use the .head() method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dP0EUH-Sawtx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "3248cd0f-d8a8-47e6-ef63-c5b5a5ee9629"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         0         1         2         3         4         5         6   \\\n",
              "0  0.772274  0.772079  0.565604  0.841941  0.446429  0.871512  0.983209   \n",
              "1  0.617835  0.617480  0.436904  0.775906  0.342186  0.773229  1.000000   \n",
              "2  0.964674  0.913374  0.681733  0.933143  0.464896  0.981104  0.992537   \n",
              "3  0.761063  0.757502  0.554467  0.841456  0.430098  0.864727  0.983831   \n",
              "4  0.635159  0.657060  0.482240  0.759716  0.460470  0.784821  0.958955   \n",
              "\n",
              "         7         8         9   ...        24        25        26        27  \\\n",
              "0  0.767108  0.787438  0.000435  ...  0.395739  0.062495  0.053715  0.080752   \n",
              "1  0.611906  0.776970  0.000282  ...  0.350002  0.037387  0.040885  0.046033   \n",
              "2  0.956896  0.736842  0.000467  ...  0.472509  0.083531  0.089677  0.096843   \n",
              "3  0.755891  0.766502  0.000408  ...  0.687121  0.136202  0.278800  0.213061   \n",
              "4  0.633316  0.711253  0.000459  ...  0.464794  0.040608  0.054459  0.086850   \n",
              "\n",
              "         28        29        30        31        32        33  \n",
              "0  0.458253  0.455197  0.546327  0.673513  0.550537  0.494665  \n",
              "1  0.687312  0.599151  0.643352  0.538923  0.516341  0.494501  \n",
              "2  0.139263  0.194220  0.312066  0.777967  0.619782  0.573507  \n",
              "3  0.707125  0.657830  0.665214  0.436260  0.377376  0.366683  \n",
              "4  0.634560  0.615256  0.710963  0.581443  0.485820  0.395128  \n",
              "\n",
              "[5 rows x 34 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7301c45f-5f70-4449-bad4-9eee6557d6be\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.772274</td>\n",
              "      <td>0.772079</td>\n",
              "      <td>0.565604</td>\n",
              "      <td>0.841941</td>\n",
              "      <td>0.446429</td>\n",
              "      <td>0.871512</td>\n",
              "      <td>0.983209</td>\n",
              "      <td>0.767108</td>\n",
              "      <td>0.787438</td>\n",
              "      <td>0.000435</td>\n",
              "      <td>...</td>\n",
              "      <td>0.395739</td>\n",
              "      <td>0.062495</td>\n",
              "      <td>0.053715</td>\n",
              "      <td>0.080752</td>\n",
              "      <td>0.458253</td>\n",
              "      <td>0.455197</td>\n",
              "      <td>0.546327</td>\n",
              "      <td>0.673513</td>\n",
              "      <td>0.550537</td>\n",
              "      <td>0.494665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.617835</td>\n",
              "      <td>0.617480</td>\n",
              "      <td>0.436904</td>\n",
              "      <td>0.775906</td>\n",
              "      <td>0.342186</td>\n",
              "      <td>0.773229</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.611906</td>\n",
              "      <td>0.776970</td>\n",
              "      <td>0.000282</td>\n",
              "      <td>...</td>\n",
              "      <td>0.350002</td>\n",
              "      <td>0.037387</td>\n",
              "      <td>0.040885</td>\n",
              "      <td>0.046033</td>\n",
              "      <td>0.687312</td>\n",
              "      <td>0.599151</td>\n",
              "      <td>0.643352</td>\n",
              "      <td>0.538923</td>\n",
              "      <td>0.516341</td>\n",
              "      <td>0.494501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.964674</td>\n",
              "      <td>0.913374</td>\n",
              "      <td>0.681733</td>\n",
              "      <td>0.933143</td>\n",
              "      <td>0.464896</td>\n",
              "      <td>0.981104</td>\n",
              "      <td>0.992537</td>\n",
              "      <td>0.956896</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>0.000467</td>\n",
              "      <td>...</td>\n",
              "      <td>0.472509</td>\n",
              "      <td>0.083531</td>\n",
              "      <td>0.089677</td>\n",
              "      <td>0.096843</td>\n",
              "      <td>0.139263</td>\n",
              "      <td>0.194220</td>\n",
              "      <td>0.312066</td>\n",
              "      <td>0.777967</td>\n",
              "      <td>0.619782</td>\n",
              "      <td>0.573507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.761063</td>\n",
              "      <td>0.757502</td>\n",
              "      <td>0.554467</td>\n",
              "      <td>0.841456</td>\n",
              "      <td>0.430098</td>\n",
              "      <td>0.864727</td>\n",
              "      <td>0.983831</td>\n",
              "      <td>0.755891</td>\n",
              "      <td>0.766502</td>\n",
              "      <td>0.000408</td>\n",
              "      <td>...</td>\n",
              "      <td>0.687121</td>\n",
              "      <td>0.136202</td>\n",
              "      <td>0.278800</td>\n",
              "      <td>0.213061</td>\n",
              "      <td>0.707125</td>\n",
              "      <td>0.657830</td>\n",
              "      <td>0.665214</td>\n",
              "      <td>0.436260</td>\n",
              "      <td>0.377376</td>\n",
              "      <td>0.366683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.635159</td>\n",
              "      <td>0.657060</td>\n",
              "      <td>0.482240</td>\n",
              "      <td>0.759716</td>\n",
              "      <td>0.460470</td>\n",
              "      <td>0.784821</td>\n",
              "      <td>0.958955</td>\n",
              "      <td>0.633316</td>\n",
              "      <td>0.711253</td>\n",
              "      <td>0.000459</td>\n",
              "      <td>...</td>\n",
              "      <td>0.464794</td>\n",
              "      <td>0.040608</td>\n",
              "      <td>0.054459</td>\n",
              "      <td>0.086850</td>\n",
              "      <td>0.634560</td>\n",
              "      <td>0.615256</td>\n",
              "      <td>0.710963</td>\n",
              "      <td>0.581443</td>\n",
              "      <td>0.485820</td>\n",
              "      <td>0.395128</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 34 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7301c45f-5f70-4449-bad4-9eee6557d6be')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7301c45f-5f70-4449-bad4-9eee6557d6be button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7301c45f-5f70-4449-bad4-9eee6557d6be');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Print the newly created DataFrame\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcTH65iLvXZu"
      },
      "source": [
        "Our features are ready for training. Now, it's time to prepare the labels. \n",
        "\n",
        "üìå Print y to take a look at it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "RCILYNj4jDsP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48cb0ec8-0999-43f5-8c37-a3a1bc5635d5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      BERHI\n",
              "1      BERHI\n",
              "2      BERHI\n",
              "3      BERHI\n",
              "4      BERHI\n",
              "       ...  \n",
              "893    SOGAY\n",
              "894    SOGAY\n",
              "895    SOGAY\n",
              "896    SOGAY\n",
              "897    SOGAY\n",
              "Name: Class, Length: 898, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Print the y array\n",
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lw9GjCZWvlM0"
      },
      "source": [
        "Artificial intelligence algorithms can't use string data when training a model because no mathematical operations can be performed on them. \n",
        "\n",
        "üìå Use the LabelEncoder of the sklearn library to converting strings to integers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "x2e_APXShCSJ"
      },
      "outputs": [],
      "source": [
        "# Create an LabelEncoder object.\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "# Convert string classes to integers using fit_transform() method\n",
        "y = encoder.fit_transform(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwPUHY_Jymbs"
      },
      "source": [
        "Then, we print y to check the result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "WfkUiTvyjPb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed55f169-dede-479c-bb57-6c98cbb0b202"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
              "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
              "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
              "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
              "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Print the y array (encoded)\n",
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NfpeVE_ypir"
      },
      "source": [
        "### Splitting\n",
        "\n",
        "Great, that worked out as we wanted it. Now, we split the dataset into training, validation and test datasets. In general, the ratio for splitting is 80% for training, 10% for validation and 10% for test sets.\n",
        "\n",
        "üìå Use train_test_split function of the sklearn library.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "iFRZLiO_klnk"
      },
      "outputs": [],
      "source": [
        "# First, create X_train, y_train and X_temporary and y_temporary datasets from X and y.\n",
        "X_train, X_temporary, y_train, y_temporary = train_test_split(X,y, train_size=0.8)\n",
        "\n",
        "# Using the X_temporary and y_temporary dataset we just created create validaiton and test datasets.\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temporary, y_temporary, train_size=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKtZg8nF_BeZ"
      },
      "source": [
        "Let's print the total length of the initial dataset and lengths of the newly created datasets to check our results.\n",
        "\n",
        "üìå Use the len() function to print the lengths."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "WK9RR2vA86yX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d45e1490-0dd2-4ce9-a5e4-5afbc6cc8af6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of dataset:898\n",
            "Length of training dataset: 718\n",
            "Length of validation dataset: 90\n",
            "Length of the test dataset: 90\n"
          ]
        }
      ],
      "source": [
        "# Print the lengths of the X, X_train, X_val and X_test\n",
        "print(f\"Length of dataset:{len(X)}\")\n",
        "print(f\"Length of training dataset: {len(X_train)}\")\n",
        "print(f\"Length of validation dataset: {len(X_val)}\")\n",
        "print(f\"Length of the test dataset: {len(X_test)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ws-STiHNNVeo"
      },
      "source": [
        "## Constructing the neural network\n",
        "And with that, our data is ready to be used in a model. We can move on to the exciting part: constructing a deep learning model. We‚Äôll use TensorFlow for this. To speed up the training time, activate the GPU of Google Colab.\n",
        "\n",
        "üìå Import TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "2f_geu61KPAh"
      },
      "outputs": [],
      "source": [
        "# Import TensorFlow\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KdShqduXUeA"
      },
      "source": [
        "Let's start by creating a model object using Sequential API of Keras.\n",
        "\n",
        "üìå Use tf.keras.Sequential() to create a model object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "3LMy6iobKUkU"
      },
      "outputs": [],
      "source": [
        "# Create a model object\n",
        "model = tf.keras.Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_VqBFFMfSpT"
      },
      "source": [
        "### Input layer\n",
        "First, we construct an input layer and assign it to a variable. The first argument is the number of nodes we want in that hidden layer. Only for the input layer, we have to set the input_shape argument which is the number of columns, in this case, 34. For the activation function, we specify ‚ÄúReLU‚Äù.\n",
        "\n",
        "üìå Use tf.keras.layers.Dense() to create the layer.\n",
        "\n",
        "üìå Use .add() method of the object to add the layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "JCpGKPkLVIwe"
      },
      "outputs": [],
      "source": [
        "# Create an input layer\n",
        "input_layer = tf.keras.layers.Dense(4096,input_shape=(34,),activation=\"relu\")\n",
        "\n",
        "# Add input layer to model object\n",
        "model.add(input_layer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGBlwZvTkYIf"
      },
      "source": [
        "### Hidden layers\n",
        "Next, we need to add the hidden layers. We'll add 4 hidden layers each with 4096 nodes. Again, we specify ReLU as the activation functions and 0.5 dropouts.\n",
        "\n",
        "üìå Use tf.keras.layers.Dense() to create the layers.\n",
        "\n",
        "üìå Use .add() method of the object to add the layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "SbuFh_whLwOM"
      },
      "outputs": [],
      "source": [
        "# Add the first hidden layer with 4096 nodes and relu activation function\n",
        "model.add(tf.keras.layers.Dense(4096,activation=\"relu\"))\n",
        "# Add 0.5 dropout\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "# Add the second hidden layer with 4096 nodes and relu activation function\n",
        "model.add(tf.keras.layers.Dense(4096,activation=\"relu\"))\n",
        "# Add 0.5 dropout\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "# Add the third hidden layer with 4096 nodes and relu activation function\n",
        "model.add(tf.keras.layers.Dense(4096,activation=\"relu\"))\n",
        "# Add 0.5 dropout\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "# Add the fourth hidden layer with 4096 nodes and relu activation function\n",
        "model.add(tf.keras.layers.Dense(4096,activation=\"relu\"))\n",
        "# Add 0.5 dropout\n",
        "model.add(tf.keras.layers.Dropout(0.5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfphgI_KkssX"
      },
      "source": [
        "### Output layer\n",
        "As the last part of our neural network, we add the output layer. The number of nodes will be equal to the number of target classes which is 7 in our case. We'll use the softmax activation function in the output layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "AjNfsMhNksPU"
      },
      "outputs": [],
      "source": [
        "# Add the output layer\n",
        "model.add(tf.keras.layers.Dense(7, activation=\"softmax\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O50WAP5MqJx-"
      },
      "source": [
        "### Optimizer\n",
        "Now we have the structure of our model. To configure the model for training, we'll use the *.compile()* method. Inside the compile method, we have to define the following:\n",
        "*   \"Adam\" for optimizer\n",
        "*   \"Sparse Categorical Crossentropy\" for the loss function\n",
        "\n",
        "\n",
        "üìå Construct the model with the .compile() method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "nO9UlFcyMywd"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer=\"adam\",loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPtfvJTQf_T2"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeIShBi8y_nG"
      },
      "source": [
        "## Training the model\n",
        "\n",
        "It's time to train the model. We'll give the X_train and y_train datasets as the first two arguments. These will be used for training. And with the *validation_data* parameter, we'll give the X_val and y_val as a tuple.\n",
        "\n",
        "üìå Use .fit() method of the model object for the training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "1huRsT3CT_Nq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efd3484b-9e1a-4f84-e526-921b1dec5063"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "23/23 [==============================] - 4s 28ms/step - loss: 1.8570 - accuracy: 0.3468 - val_loss: 1.1182 - val_accuracy: 0.6222\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.8966 - accuracy: 0.6518 - val_loss: 0.7091 - val_accuracy: 0.7111\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.7003 - accuracy: 0.7159 - val_loss: 0.5511 - val_accuracy: 0.7444\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.5999 - accuracy: 0.7632 - val_loss: 0.4399 - val_accuracy: 0.8111\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.5507 - accuracy: 0.7758 - val_loss: 0.5681 - val_accuracy: 0.7333\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.5358 - accuracy: 0.7841 - val_loss: 0.4684 - val_accuracy: 0.7556\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.4879 - accuracy: 0.8148 - val_loss: 0.4917 - val_accuracy: 0.8000\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.5093 - accuracy: 0.7953 - val_loss: 0.3194 - val_accuracy: 0.8444\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.4004 - accuracy: 0.8468 - val_loss: 0.4228 - val_accuracy: 0.8333\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.4542 - accuracy: 0.8273 - val_loss: 0.3333 - val_accuracy: 0.8778\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.4473 - accuracy: 0.8343 - val_loss: 0.3130 - val_accuracy: 0.8667\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.4460 - accuracy: 0.8106 - val_loss: 0.3520 - val_accuracy: 0.8667\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.4574 - accuracy: 0.8440 - val_loss: 0.4738 - val_accuracy: 0.8222\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.4961 - accuracy: 0.8078 - val_loss: 0.3298 - val_accuracy: 0.8889\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.4282 - accuracy: 0.8384 - val_loss: 0.2854 - val_accuracy: 0.9111\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.3413 - accuracy: 0.8621 - val_loss: 0.3490 - val_accuracy: 0.8222\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 0s 19ms/step - loss: 0.3343 - accuracy: 0.8760 - val_loss: 0.3497 - val_accuracy: 0.8667\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.4031 - accuracy: 0.8482 - val_loss: 0.3032 - val_accuracy: 0.8778\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.5016 - accuracy: 0.8189 - val_loss: 0.4826 - val_accuracy: 0.7889\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.4068 - accuracy: 0.8468 - val_loss: 0.2518 - val_accuracy: 0.9222\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.3565 - accuracy: 0.8802 - val_loss: 0.3396 - val_accuracy: 0.8778\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.3287 - accuracy: 0.8691 - val_loss: 0.4001 - val_accuracy: 0.8778\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.4193 - accuracy: 0.8621 - val_loss: 0.2505 - val_accuracy: 0.9000\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.3456 - accuracy: 0.8858 - val_loss: 0.4558 - val_accuracy: 0.8111\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.4094 - accuracy: 0.8663 - val_loss: 0.2923 - val_accuracy: 0.8556\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.3502 - accuracy: 0.8760 - val_loss: 0.3974 - val_accuracy: 0.8667\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.4059 - accuracy: 0.8510 - val_loss: 0.4153 - val_accuracy: 0.8556\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.3409 - accuracy: 0.8691 - val_loss: 0.2805 - val_accuracy: 0.9111\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.3306 - accuracy: 0.8858 - val_loss: 0.2229 - val_accuracy: 0.9222\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.3147 - accuracy: 0.8788 - val_loss: 0.2514 - val_accuracy: 0.9111\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.3260 - accuracy: 0.8900 - val_loss: 0.3112 - val_accuracy: 0.8556\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.3383 - accuracy: 0.8802 - val_loss: 0.2797 - val_accuracy: 0.8889\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.3476 - accuracy: 0.8802 - val_loss: 0.3350 - val_accuracy: 0.8778\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.3102 - accuracy: 0.8928 - val_loss: 0.1662 - val_accuracy: 0.9333\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.3105 - accuracy: 0.8942 - val_loss: 0.3523 - val_accuracy: 0.8556\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.3086 - accuracy: 0.8844 - val_loss: 0.4306 - val_accuracy: 0.8444\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 0s 19ms/step - loss: 0.2939 - accuracy: 0.8886 - val_loss: 0.1895 - val_accuracy: 0.9111\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 0s 19ms/step - loss: 0.3070 - accuracy: 0.8900 - val_loss: 0.2987 - val_accuracy: 0.8556\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.3797 - accuracy: 0.8621 - val_loss: 0.4357 - val_accuracy: 0.8778\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.3489 - accuracy: 0.8733 - val_loss: 0.2562 - val_accuracy: 0.8444\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 0s 20ms/step - loss: 0.3514 - accuracy: 0.8705 - val_loss: 0.2136 - val_accuracy: 0.9111\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2306 - accuracy: 0.9150 - val_loss: 0.2242 - val_accuracy: 0.9222\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.3142 - accuracy: 0.9025 - val_loss: 0.3084 - val_accuracy: 0.8667\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.3223 - accuracy: 0.8788 - val_loss: 0.4811 - val_accuracy: 0.8556\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.3801 - accuracy: 0.8579 - val_loss: 0.2644 - val_accuracy: 0.8889\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2815 - accuracy: 0.9081 - val_loss: 0.2446 - val_accuracy: 0.9000\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2807 - accuracy: 0.8997 - val_loss: 0.2204 - val_accuracy: 0.9222\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2651 - accuracy: 0.9150 - val_loss: 0.1933 - val_accuracy: 0.9444\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2622 - accuracy: 0.8928 - val_loss: 0.2025 - val_accuracy: 0.9111\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.3468 - accuracy: 0.8816 - val_loss: 0.2905 - val_accuracy: 0.8778\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2583 - accuracy: 0.9095 - val_loss: 0.1818 - val_accuracy: 0.9222\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2775 - accuracy: 0.8955 - val_loss: 0.2198 - val_accuracy: 0.9000\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2570 - accuracy: 0.9164 - val_loss: 0.2747 - val_accuracy: 0.8667\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2595 - accuracy: 0.9109 - val_loss: 0.2681 - val_accuracy: 0.9000\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2788 - accuracy: 0.9081 - val_loss: 0.1696 - val_accuracy: 0.9556\n",
            "Epoch 56/100\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.3141 - accuracy: 0.8886 - val_loss: 0.2924 - val_accuracy: 0.8889\n",
            "Epoch 57/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2575 - accuracy: 0.9150 - val_loss: 0.2455 - val_accuracy: 0.9222\n",
            "Epoch 58/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.3248 - accuracy: 0.8955 - val_loss: 0.2809 - val_accuracy: 0.9222\n",
            "Epoch 59/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2874 - accuracy: 0.8928 - val_loss: 0.2176 - val_accuracy: 0.9000\n",
            "Epoch 60/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2877 - accuracy: 0.8928 - val_loss: 0.2826 - val_accuracy: 0.8778\n",
            "Epoch 61/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2317 - accuracy: 0.9178 - val_loss: 0.4438 - val_accuracy: 0.8667\n",
            "Epoch 62/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.3324 - accuracy: 0.8914 - val_loss: 0.2519 - val_accuracy: 0.8889\n",
            "Epoch 63/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2341 - accuracy: 0.9206 - val_loss: 0.1886 - val_accuracy: 0.9444\n",
            "Epoch 64/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2782 - accuracy: 0.9025 - val_loss: 0.2146 - val_accuracy: 0.9222\n",
            "Epoch 65/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.3095 - accuracy: 0.8788 - val_loss: 0.2582 - val_accuracy: 0.9222\n",
            "Epoch 66/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.3168 - accuracy: 0.8747 - val_loss: 0.4545 - val_accuracy: 0.8444\n",
            "Epoch 67/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2881 - accuracy: 0.8942 - val_loss: 0.4437 - val_accuracy: 0.8444\n",
            "Epoch 68/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2578 - accuracy: 0.9136 - val_loss: 0.2429 - val_accuracy: 0.8667\n",
            "Epoch 69/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2875 - accuracy: 0.8955 - val_loss: 0.3128 - val_accuracy: 0.8778\n",
            "Epoch 70/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2849 - accuracy: 0.8997 - val_loss: 0.3287 - val_accuracy: 0.8889\n",
            "Epoch 71/100\n",
            "23/23 [==============================] - 0s 19ms/step - loss: 0.2959 - accuracy: 0.8955 - val_loss: 0.5080 - val_accuracy: 0.8000\n",
            "Epoch 72/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.3138 - accuracy: 0.8872 - val_loss: 0.2542 - val_accuracy: 0.9222\n",
            "Epoch 73/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2163 - accuracy: 0.9150 - val_loss: 0.1651 - val_accuracy: 0.9222\n",
            "Epoch 74/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2361 - accuracy: 0.9150 - val_loss: 0.3290 - val_accuracy: 0.9222\n",
            "Epoch 75/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2575 - accuracy: 0.9136 - val_loss: 0.3683 - val_accuracy: 0.8222\n",
            "Epoch 76/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2592 - accuracy: 0.9095 - val_loss: 0.2362 - val_accuracy: 0.9111\n",
            "Epoch 77/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2475 - accuracy: 0.9136 - val_loss: 0.1965 - val_accuracy: 0.9444\n",
            "Epoch 78/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2692 - accuracy: 0.9109 - val_loss: 0.1697 - val_accuracy: 0.9333\n",
            "Epoch 79/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2487 - accuracy: 0.9150 - val_loss: 0.2289 - val_accuracy: 0.8778\n",
            "Epoch 80/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2776 - accuracy: 0.8955 - val_loss: 0.2839 - val_accuracy: 0.8778\n",
            "Epoch 81/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.3226 - accuracy: 0.8747 - val_loss: 0.2481 - val_accuracy: 0.8889\n",
            "Epoch 82/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2805 - accuracy: 0.9206 - val_loss: 0.2765 - val_accuracy: 0.8889\n",
            "Epoch 83/100\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2569 - accuracy: 0.9081 - val_loss: 0.3238 - val_accuracy: 0.9111\n",
            "Epoch 84/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2183 - accuracy: 0.9136 - val_loss: 0.1590 - val_accuracy: 0.9222\n",
            "Epoch 85/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.3099 - accuracy: 0.9067 - val_loss: 0.2814 - val_accuracy: 0.8556\n",
            "Epoch 86/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.3430 - accuracy: 0.8733 - val_loss: 0.2917 - val_accuracy: 0.9111\n",
            "Epoch 87/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2764 - accuracy: 0.9025 - val_loss: 0.1692 - val_accuracy: 0.9333\n",
            "Epoch 88/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2388 - accuracy: 0.9192 - val_loss: 0.2865 - val_accuracy: 0.8889\n",
            "Epoch 89/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.1875 - accuracy: 0.9276 - val_loss: 0.3510 - val_accuracy: 0.8889\n",
            "Epoch 90/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2788 - accuracy: 0.8997 - val_loss: 0.1988 - val_accuracy: 0.8889\n",
            "Epoch 91/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2867 - accuracy: 0.8969 - val_loss: 0.2118 - val_accuracy: 0.9222\n",
            "Epoch 92/100\n",
            "23/23 [==============================] - 0s 21ms/step - loss: 0.3691 - accuracy: 0.8788 - val_loss: 0.4475 - val_accuracy: 0.8667\n",
            "Epoch 93/100\n",
            "23/23 [==============================] - 0s 20ms/step - loss: 0.2368 - accuracy: 0.9081 - val_loss: 0.3818 - val_accuracy: 0.8667\n",
            "Epoch 94/100\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.2182 - accuracy: 0.9178 - val_loss: 0.3716 - val_accuracy: 0.8889\n",
            "Epoch 95/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2121 - accuracy: 0.9164 - val_loss: 0.3679 - val_accuracy: 0.8667\n",
            "Epoch 96/100\n",
            "23/23 [==============================] - 1s 22ms/step - loss: 0.2187 - accuracy: 0.9136 - val_loss: 0.1923 - val_accuracy: 0.9111\n",
            "Epoch 97/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2702 - accuracy: 0.9025 - val_loss: 0.1959 - val_accuracy: 0.9444\n",
            "Epoch 98/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2180 - accuracy: 0.9248 - val_loss: 0.2148 - val_accuracy: 0.9222\n",
            "Epoch 99/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.1697 - accuracy: 0.9318 - val_loss: 0.2973 - val_accuracy: 0.9000\n",
            "Epoch 100/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.1940 - accuracy: 0.9206 - val_loss: 0.3401 - val_accuracy: 0.9222\n"
          ]
        }
      ],
      "source": [
        "# Train the model for 100 epochs \n",
        "results= model.fit(X_train, y_train, epochs=100, validation_data=(X_val,y_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYIh2nkQYsu-"
      },
      "source": [
        "### Visualize the results\n",
        "\n",
        "After the model is trained, we can create a graph to visualize the change of loss over time. Results are held in:\n",
        "* results.history[\"loss\"]\n",
        "* results.history[\"val_loss\"]\n",
        "\n",
        "üìå Use plt.show() to display the graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "uzfcUsLdjvmX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "e782ac55-2328-426d-b5ed-eea4b0a97ff1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Plot the the training loss\n",
        "plt.plot(results.history[\"loss\"], label=\"Train\")\n",
        "# Plot the the validation loss\n",
        "plt.plot(results.history[\"val_loss\"], label=\"Test\")\n",
        "# Name the x and y axises\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "# Put legend table\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEPY1Jmh-aBW"
      },
      "source": [
        "## Performance evaluation\n",
        "\n",
        "Finally, we are going to use the test dataset we created to evaluate the performance of the model.\n",
        "\n",
        "üìå Use test_on_batch() method with test dataset as parameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "4STruM9vy_3l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88e2ada5-4868-4633-c2fb-68511e424b28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.2560669779777527, 0.8777777552604675]\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the performance\n",
        "test_result = model.test_on_batch(X_test,y_test)\n",
        "# Print the result\n",
        "print(test_result)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}